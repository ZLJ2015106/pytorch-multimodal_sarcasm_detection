{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import ImageFeature\n",
    "import AttributeFeature\n",
    "import TextFeature\n",
    "import FinalClassifier\n",
    "import FuseAllFeature\n",
    "from LoadData import *\n",
    "from torch.utils.data import Dataset, DataLoader,random_split\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Multimodel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Multimodel, self).__init__()\n",
    "        self.image = ImageFeature.ExtractImageFeature()\n",
    "        self.attribute = AttributeFeature.ExtractAttributeFeature()\n",
    "        self.text = TextFeature.ExtractTextFeature(TEXT_LENGTH, TEXT_HIDDEN)\n",
    "        self.fuse = FuseAllFeature.ModalityFusion()\n",
    "        self.final_classifier = FinalClassifier.ClassificationLayer()\n",
    "    def forward(self, text_index, image_feature, attribute_index):\n",
    "        image_result,image_seq = self.image(image_feature)\n",
    "        attribute_result,attribute_seq = self.attribute(attribute_index)\n",
    "        text_result,text_seq = self.text(text_index,attribute_result)\n",
    "        fusion = self.fuse(image_result,image_seq,text_result,text_seq.permute(1,0,2),attribute_result,attribute_seq.permute(1,0,2))\n",
    "        output = self.final_classifier(fusion)\n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "# loss_fn = torch.nn.MSELoss(reduction=\n",
    "loss_fn=torch.nn.BCELoss()\n",
    "# learning rate\n",
    "learning_rate = 0.001\n",
    "# initilize the model\n",
    "model = Multimodel().to(device)\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,weight_decay=1e-7)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 train_loss=0.48695 train_acc=0.759 valid_loss=0.43708 valid_acc=0.796\n",
      "epoch: 1 train_loss=0.41078 train_acc=0.813 valid_loss=0.40752 valid_acc=0.822\n",
      "epoch: 2 train_loss=0.37029 train_acc=0.835 valid_loss=0.43805 valid_acc=0.804\n",
      "epoch: 3 train_loss=0.33806 train_acc=0.852 valid_loss=0.42840 valid_acc=0.805\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-4-9ad8de4c63e6>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     11\u001B[0m         \u001B[0mcorrect_train\u001B[0m\u001B[1;33m+=\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpred\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mround\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m==\u001B[0m\u001B[0mgroup\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msum\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mitem\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     12\u001B[0m         \u001B[0moptimizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mzero_grad\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 13\u001B[1;33m         \u001B[0mloss\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     14\u001B[0m         \u001B[0moptimizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32me:\\python\\python37\\lib\\site-packages\\torch\\tensor.py\u001B[0m in \u001B[0;36mbackward\u001B[1;34m(self, gradient, retain_graph, create_graph)\u001B[0m\n\u001B[0;32m    183\u001B[0m                 \u001B[0mproducts\u001B[0m\u001B[1;33m.\u001B[0m \u001B[0mDefaults\u001B[0m \u001B[0mto\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m`\u001B[0m\u001B[0;31m`\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[0;31m`\u001B[0m\u001B[0;31m`\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    184\u001B[0m         \"\"\"\n\u001B[1;32m--> 185\u001B[1;33m         \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mautograd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgradient\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    186\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    187\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mregister_hook\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mhook\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32me:\\python\\python37\\lib\\site-packages\\torch\\autograd\\__init__.py\u001B[0m in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001B[0m\n\u001B[0;32m    125\u001B[0m     Variable._execution_engine.run_backward(\n\u001B[0;32m    126\u001B[0m         \u001B[0mtensors\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgrad_tensors\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 127\u001B[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001B[0m\u001B[0;32m    128\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    129\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "number_of_epoch=100\n",
    "for epoch in range(number_of_epoch):\n",
    "\n",
    "    train_loss=0\n",
    "    correct_train=0\n",
    "    model.train()\n",
    "    for text_index, image_feature, attribute_index, group, id in train_loader:\n",
    "        group = group.view(-1,1).to(torch.float32).to(device)\n",
    "        pred = model(text_index.to(device), image_feature.to(device), attribute_index.to(device))\n",
    "        loss = loss_fn(pred, group)\n",
    "        train_loss+=loss\n",
    "        correct_train+=(pred.round()==group).sum().item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # calculate valid loss\n",
    "\n",
    "    valid_loss=0\n",
    "    correct_valid=0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for val_text_index, val_image_feature, val_attribute_index, val_group, val_id in val_loader:\n",
    "            val_group = val_group.view(-1,1).to(torch.float32).to(device)\n",
    "            val_pred = model(val_text_index.to(device), val_image_feature.to(device), val_attribute_index.to(device))\n",
    "            val_loss = loss_fn(val_pred, val_group)\n",
    "            valid_loss+=val_loss\n",
    "            correct_valid+=(val_pred.round()==val_group).sum().item()\n",
    "\n",
    "    print(\"epoch: %d train_loss=%.5f train_acc=%.3f valid_loss=%.5f valid_acc=%.3f\"%(epoch,\n",
    "                                                                                     train_loss/len(train_loader),\n",
    "                                                                                  correct_train/len(train_loader)/batch_size,\n",
    "                                                                                     valid_loss/len(val_loader),\n",
    "                                                                                     correct_valid/len(val_loader)/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import seaborn as sns\n",
    "def validation_metrics (model, dataset):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total=0\n",
    "        correct=0\n",
    "        confusion_matrix_sum=None\n",
    "        loss_sum=0\n",
    "        for text_index, image_feature, attribute_index, group, id in dataset:\n",
    "            group = group.view(-1,1).to(torch.float32).to(device)\n",
    "            pred = model(text_index.to(device), image_feature.to(device), attribute_index.to(device))\n",
    "            loss = loss_fn(pred, group)\n",
    "            loss_sum+=loss\n",
    "            correct+=(pred.round()==group).sum().item()\n",
    "            # calculate confusion matrix\n",
    "            if confusion_matrix_sum is None:\n",
    "                confusion_matrix_sum=sklearn.metrics.confusion_matrix(group.to(\"cpu\"),pred.to(\"cpu\"),labels=[0,1])\n",
    "            else:\n",
    "                confusion_matrix_sum+=sklearn.metrics.confusion_matrix(group.to(\"cpu\"),pred.to(\"cpu\"),labels=[0,1])\n",
    "        acc=correct/total\n",
    "        loss_avg=loss_sum/len(dataset)\n",
    "    return loss_avg.item(), acc, confusion_matrix_sum\n",
    "\n",
    "def plot_confusion_matrix(confusion_matrix):\n",
    "    emotions=['not sarcasm','sarcasm']\n",
    "    sns.heatmap(confusion_matrix, annot=True, xticklabels=emotions, yticklabels=emotions)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n",
    "loss, acc, confusion_matrix=validation_metrics (model, test_loader)\n",
    "print(\"loss:\",loss,\"accuracy:\",acc)\n",
    "plot_confusion_matrix(confusion_matrix)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib as plt\n",
    "def validation_metrics (model, dataset):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        count=0\n",
    "        for text_index, image_feature, attribute_index, group, id in dataset:\n",
    "            if count==5:\n",
    "                break\n",
    "            print(f\">>>Example 1<<<\")\n",
    "            img=dataset.image_loader(id)\n",
    "            plt.imshow(img[0].permute(1,2,0))\n",
    "            plt.show()\n",
    "            print(\"Text: \",dataset.text_loader(id))\n",
    "            print(\"Labels: \",dataset.label_loader(id))\n",
    "            print(f\"Truth:{' not ' if group[0]==0 else ' '}sarcasm\")\n",
    "            pred = model(text_index.to(device), image_feature.to(device), attribute_index.to(device))\n",
    "            print(f\"Preduct:{' not ' if round(pred[0,0])==0 else ' '}sarcasm\")\n",
    "            count+=1\n",
    "\n",
    "validation_metrics (model, play_loader)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}